import os
import yaml
from pydantic import Field, validator
from typing import Optional, Union

from medperf.utils import remove_path
from medperf.entities.interface import Entity
from medperf.entities.schemas import DeployableSchema

import medperf.config as config
from medperf.account_management import get_medperf_user_data


class Dataset(Entity, DeployableSchema):
    """
    Class representing a Dataset

    Datasets are stored locally in the Data Owner's machine. They contain
    information regarding the prepared dataset, such as name and description,
    general statistics and an UID generated by hashing the contents of the
    data preparation output.
    """

    description: Optional[str] = Field(None, max_length=20)
    location: Optional[str] = Field(None, max_length=20)
    input_data_hash: str
    generated_uid: str
    data_preparation_mlcube: Union[int, str]
    split_seed: Optional[int]
    generated_metadata: dict = Field(..., alias="metadata")
    user_metadata: dict = {}
    report: dict = {}
    submitted_as_prepared: bool

    @staticmethod
    def get_type():
        return "dataset"

    @staticmethod
    def get_storage_path():
        return config.datasets_folder

    @staticmethod
    def get_comms_retriever():
        return config.comms.get_dataset

    @staticmethod
    def get_metadata_filename():
        return config.reg_file

    @staticmethod
    def get_comms_uploader():
        return config.comms.upload_dataset

    @validator("data_preparation_mlcube", pre=True, always=True)
    def check_data_preparation_mlcube(cls, v, *, values, **kwargs):
        if not isinstance(v, int) and not values["for_test"]:
            raise ValueError(
                "data_preparation_mlcube must be an integer if not running a compatibility test"
            )
        return v

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.local_id = self.generated_uid
        self.data_path = os.path.join(self.path, "data")
        self.labels_path = os.path.join(self.path, "labels")
        self.report_path = os.path.join(self.path, config.report_file)
        self.metadata_path = os.path.join(self.path, config.metadata_folder)
        self.statistics_path = os.path.join(self.path, config.statistics_filename)

    def set_raw_paths(self, raw_data_path: str, raw_labels_path: str):
        raw_paths_file = os.path.join(self.path, config.dataset_raw_paths_file)
        data = {"data_path": raw_data_path, "labels_path": raw_labels_path}
        with open(raw_paths_file, "w") as f:
            yaml.dump(data, f)

    def get_raw_paths(self):
        raw_paths_file = os.path.join(self.path, config.dataset_raw_paths_file)
        with open(raw_paths_file) as f:
            data = yaml.safe_load(f)
        return data["data_path"], data["labels_path"]

    def mark_as_ready(self):
        flag_file = os.path.join(self.path, config.ready_flag_file)
        with open(flag_file, "w"):
            pass

    def unmark_as_ready(self):
        flag_file = os.path.join(self.path, config.ready_flag_file)
        remove_path(flag_file)

    def is_ready(self):
        flag_file = os.path.join(self.path, config.ready_flag_file)
        return os.path.exists(flag_file)

    @classmethod
    def _Entity__remote_prefilter(cls, filters: dict) -> callable:
        """Applies filtering logic that must be done before retrieving remote entities

        Args:
            filters (dict): filters to apply

        Returns:
            callable: A function for retrieving remote entities with the applied prefilters
        """
        comms_fn = config.comms.get_datasets
        if "owner" in filters and filters["owner"] == get_medperf_user_data()["id"]:
            comms_fn = config.comms.get_user_datasets

        if "mlcube" in filters and filters["mlcube"] is not None:

            def func():
                return config.comms.get_mlcube_datasets(filters["mlcube"])

            comms_fn = func

        return comms_fn

    def display_dict(self):
        return {
            "UID": self.identifier,
            "Name": self.name,
            "Description": self.description,
            "Location": self.location,
            "Data Preparation Cube UID": self.data_preparation_mlcube,
            "Generated Hash": self.generated_uid,
            "State": self.state,
            "Created At": self.created_at,
            "Registered": self.is_registered,
            "Submitted as Prepared": self.submitted_as_prepared,
            "Status": "\n".join([f"{k}: {v}" for k, v in self.report.items()]),
            "Owner": self.owner,
        }
