## Purpose:
At the time of writing, metrics MLCubes have the only purpose of computing metrics on predictions. The receives the predictions generated by the model, and the output of the data preparation cube in order to extract labels and calculate the model's performance.

## How to run:
This template was built so it can work out-of-the-box. Follow the next steps:

1. Clone the repository
2. cd to the repository
   ```bash
   cd mlcube_examples
   ```
3. Install mlcube and mlcube-docker

   ```bash
   pip install mlcube mlcube-docker
   ```
4. cd to current example's `mlcube` folder

   ```bash
   cd medperf/metrics/mlcube
   ```
5. execute the `evaluate` task with mlcube
   ```bash
   mlcube run --task=infer -Pdocker.build_strategy=auto
   ```
6. check resulting predictions
   ```bash
   cat workspace/results.yaml
   ```
That's it! You just built and ran a hello-world metrics mlcube!

## Contents

MLCubes usually share a similar folder structure and files. Here's a brief description of the role for the relevant files

1. __`mlcube/mlcube.yaml`__: 
   
   The `mlcube.yaml` file contains metadata about your project, including its interface. For MedPerf, we require an `evaluate` function that takes in (at minimum) arguments for `predictions`, `labels` and `parameters_file` and outputs model performance artifacts inside the `output_path`. You see this definition in the mlcube.yaml file as:

    ```yml
    tasks:
        # Metrics MLCubes require only a single task: `evaluate`
        # This tast takes the predictions generated by the model mlcube (as a directory)
        # and the output of the Data Preparation MLCube containing the labels (as a directory)
        # to compute metrics, which are then stored inside the output_path 
        evaluate:
        # Executes a number of metrics specified by the params file
            parameters:
            inputs: {
                predictions: predictions,                            # Required. Where to find the predictions. MUST be a folder
                labels: labels,                                      # Required. Where to find the labels. MUST be a folder
                parameters_file: parameters.yaml                     # Required. Helper file to provide additional arguments. Value MUST be parameters.yaml
                # If you need any additional files that should 
                # not be included inside the mlcube image, 
                # add them inside `additional_files` folder
            }
            outputs: {
                output_path: {type: "file", default: "results.yaml"} # Required. Where to write the metrics results. Value MUST be results.yaml
            }
    ```
    The output generated by the metrics mlcube is expected to be a file named `results.yaml`, which contains the results of the computed metrics.

2. __`mlcube/workspace/parameters.yaml`__:

   This file provides ways to parameterize your model. You can set any key-value pairs that should be easily modifiable in order to adjust you model's behavior. Current example shows how we can specify the metrics we want to compute (`metrics`), for what labels (`label columns`), and the column we use for identifying each true-label/prediction (`id column`):
   ```yml
        # File for parametrizing your metrics calculations

        metrics:
        # List of metrics to run
        - ACC

        label columns:
        # Label columns that are going to be evaluated
        - greeting

        # Common identifier column for labels and predictions
        id column: id
   ```

   This structure follows how we've been specifying metrics parametrization. Your metrics don't need to follow this parameters structure.

3. __`mlcube/workspace/additional_files/*`__:
   
   You may require additional files that should not be packaged inside the mlcube (due to size or usability constrains) like weights. For these cases, we provide an additional folder called `additional_files`. Here, you can provide any other files that should be present at the time of inference. At the time of mlcube registration, this folder must be compressed into a tarball (`.tar.gz`) and hosted somewhere on the web. MedPerf will then be able to download, verify and reposition those files in the expected location for mlcube execution. 



4. __`project`__: 
   
   Contains the actual implementation of the mlcube. This includes all project-specific code, `Dockerfile` for building docker containers of the project and requirements for running the code.

5. __`project/mlcube.py`__:
   
   MLCube expects an entrypoint to the project in order to run the code and the specified tasks. It expects this entrypoint to behave like a CLI, in which each MLCube task (e.g. `evaluate`) is executed as a subcommand, and each input/output parameter is passed as a CLI argument. An example of the expected interface is:
   ```bash
    python3 project/mlcube.py evaluate --predictions=<PREDICTIONS_PATH>  --labels=<LABELS_PATH> --parameters_file=<PARAMETERS_FILE> --output_path=<OUTPUT_PATH>
   ```
   `mlcube.py` provides such interface for this toy example. As long as you follow such CLI interface, you can implement it however you want. We provide an example that requirems minimal modifications to the original project code, by running any project task through subprocesses.

   #### __What is that “hotfix” function I see in mlcube.py?__

    In short, it’s benign and there to avoid a potential cli issue, so you can just leave it and forget about it.

    For those who care, when using typer/click for your cli, like we do, you need more than one @app.command, or typer/click will not parse the command-line in the way mlcube expects. This is a silly, known issue that goes away as soon as you have more than one task in your mlcube interface. But since our model cubes currently only have one task, we add an extra, blank typer command to avoid this issue. If you don’t use typer/click, you likely don’t need this dummy command.

## How to modify
If you want to adjust this template for your own use-case, then the following list serves as a step-by-step guide:
1. Remove demo artifacts from `/mlcube/workspace`: 
     - `/mlcube/workspace/labels/*`
     - `/mlcube/workspace/predictions/*`
     - `/mlcube/workspace/`
2. Pass your original code to the `/project` folder (removing `app.py`) 
3. Adjust your code and the `/project/mlcube.py` file so that commands point to the respective code and receive the expected arguments
4. Modify `/project/requirements.txt` so that it contains all code dependencies for your project
5. Default `/project/Dockerfile` should suffice, but feel free to add/modify it to work with your needs. As long as it has an entrypoint pointing to `mlcube.py`
6. Inside `/mlcube/workspace` add the data you want your cube to compute metrics for
7. Inside `/mlcube/workspace/additional_files` add any additional files that are required for metrics execution
8. Adjust `/mlcube/mlcube.yaml` so that:
   1. metadata such as `name`, `description`, `authors` and `image_name` are correctly assigned.
   2. `labels` points to the location where you expect labels to be inside the `workspace` directory.
   3. `predictions` points to the location where you expect predictions to be inside the `workspace` directory.
   4. `parameters_file` should NOT be modified in any way.
   6. Add any other required parameters that point to `additional_files`. Naming can be arbitrary, but all files referenced from now on should be contained inside `additional_files`.
   7. `output_path` should NOT be modified in any way.

## Requirements are negotiable
The required fields in the mlcube task interface show what medperf currently assumes. As we are in alpha, this is a great time to raise concerns or requests about these requirements! Now is the best time for us to make changes.
