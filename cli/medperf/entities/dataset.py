import os
from medperf.enums import Status
import yaml
import logging
from typing import List

from medperf.utils import (
    get_uids,
    pretty_error,
    storage_path,
)
from medperf.entities.interface import Entity
import medperf.config as config


class Dataset(Entity):
    """
    Class representing a Dataset

    Datasets are stored locally in the Data Owner's machine. They contain
    information regarding the prepared dataset, such as name and description,
    general statistics and an UID generated by hashing the contents of the
    data preparation output.
    """

    def __init__(self, data_uid: int, registration=None):
        """Creates a new dataset instance

        Args:
            data_uid (int): The dataset UID as found inside ~/medperf/data/

        Raises:
            NameError: If the dataset with the given UID can't be found, this is thrown.
        """
        if registration is None:
            data_uid = self.__full_uid(data_uid)
            self.generated_uid = data_uid
            self.dataset_path = os.path.join(
                storage_path(config.data_storage), str(data_uid)
            )
            registration = self.get_registration()
        else:
            # in this case, the passed data_uid will not be used
            self.generated_uid = registration["generated_uid"]
            self.dataset_path = os.path.join(
                storage_path(config.data_storage), str(self.generated_uid)
            )
        self.data_path = os.path.join(self.dataset_path, "data")
        self.uid = registration["uid"]
        self.name = registration["name"]
        self.description = registration["description"]
        self.location = registration["location"]
        self.preparation_cube_uid = registration["data_preparation_mlcube"]
        self.input_data_hash = registration["input_data_hash"]
        self.separate_labels = registration.get("separate_labels", False)
        self.split_seed = registration["split_seed"]
        if "metadata" in registration:
            # Make sure it is backwards-compatible
            self.generated_metadata = registration["metadata"]
        else:
            self.generated_metadata = registration["generated_metadata"]
        self.status = Status(registration["status"])
        self.state = registration["state"]

        self.labels_path = self.data_path
        if self.separate_labels:
            self.labels_path = os.path.join(self.dataset_path, "labels")

    @property
    def registration(self):
        return {
            "uid": self.uid,
            "name": self.name,
            "description": self.description,
            "location": self.location,
            "data_preparation_mlcube": self.preparation_cube_uid,
            "input_data_hash": self.input_data_hash,
            "generated_uid": self.generated_uid,
            "split_seed": self.split_seed,
            "generated_metadata": self.generated_metadata,
            "status": self.status.value,
            "state": self.state,
            "separate_labels": self.separate_labels,
        }

    @classmethod
    def all(cls) -> List["Dataset"]:
        """Gets and creates instances of all the locally prepared datasets

        Returns:
            List[Dataset]: a list of Dataset instances.
        """
        logging.info("Retrieving all datasets")
        data_storage = storage_path(config.data_storage)
        try:
            generated_uids = next(os.walk(data_storage))[1]
        except StopIteration:
            logging.warning("Couldn't iterate over the dataset directory")
            pretty_error("Couldn't iterate over the dataset directory")
        tmp_prefix = config.tmp_prefix
        dsets = []
        for generated_uid in generated_uids:
            not_tmp = not generated_uid.startswith(tmp_prefix)
            reg_path = os.path.join(data_storage, generated_uid, config.reg_file)
            registered = os.path.exists(reg_path)
            if not_tmp and registered:
                dsets.append(cls(generated_uid))
        return dsets

    @classmethod
    def get(cls, dset_uid: str) -> "Dataset":
        """Retrieves and creates a Dataset instance from the comms instance.
        If the dataset is present in the user's machine then it retrieves it from there.

        Args:
            dset_uid (str): server UID of the dataset

        Returns:
            Dataset: Specified Dataset Instance
        """
        logging.debug(f"Retrieving dataset {dset_uid}")
        comms = config.comms
        local_dset = list(
            filter(lambda dset: str(dset.uid) == str(dset_uid), cls.all())
        )
        if len(local_dset) == 1:
            logging.debug("Found dataset locally")
            return local_dset[0]

        meta = comms.get_dataset(dset_uid)
        return cls(None, registration=meta)

    def __full_uid(self, uid_hint: str) -> str:
        """Returns the found UID that starts with the provided UID hint

        Args:
            uid_hint (int): a small initial portion of an existing local dataset UID

        Raises:
            NameError: If no dataset is found starting with the given hint, this is thrown.
            NameError: If multiple datasets are found starting with the given hint, this is thrown.

        Returns:
            str: the complete UID
        """
        data_storage = storage_path(config.data_storage)
        dsets = get_uids(data_storage)
        match = [uid for uid in dsets if uid.startswith(str(uid_hint))]
        if len(match) == 0:
            pretty_error(f"No dataset was found with uid hint {uid_hint}.")
        elif len(match) > 1:
            pretty_error(f"Multiple datasets were found with uid hint {uid_hint}.")
        else:
            return match[0]

    def get_registration(self) -> dict:
        """Retrieves the registration information.

        Returns:
            dict: registration information as key-value pairs.
        """
        regfile = os.path.join(self.dataset_path, config.reg_file)
        with open(regfile, "r") as f:
            reg = yaml.safe_load(f)
        return reg

    def set_registration(self):
        logging.info(f"Updating registration information for dataset: {self.uid}")
        logging.debug(f"registration information: {self.registration}")
        regfile = os.path.join(self.dataset_path, config.reg_file)
        with open(regfile, "w") as f:
            yaml.dump(self.registration, f)

    def todict(self):
        return self.registration

    def upload(self):
        """Uploads the registration information to the comms.

        Args:
            comms (Comms): Instance of the comms interface.
        """
        dataset_uid = config.comms.upload_dataset(self.todict())
        self.uid = dataset_uid
        return self.uid
